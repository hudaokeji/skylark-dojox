{"version":3,"sources":["string/tokenize.js"],"names":["define","lang","has","getObject","tokenize","str","re","parseDelim","instance","match","content","tokens","lastIndex","exec","slice","length","push","copy","parsed","apply","concat"],"mappings":";;;;;;;AAAAA,QACC,kBACA,oBACE,SAASC,EAAMC,GACFD,EAAKE,UAAU,gBAAgB,GAAMC,SAsCpD,OApCW,SAAoBC,EAAgBC,EAAkBC,EAAwBC,GAUxF,IAFA,IACIC,EAAOC,EADPC,KACgBC,EAAY,EAC1BH,EAAQH,EAAGO,KAAKR,IAAK,CAK1B,IAJAK,EAAUL,EAAIS,MAAMF,EAAWN,EAAGM,UAAYH,EAAM,GAAGM,SAC5CA,QACVJ,EAAOK,KAAKN,GAEVH,EAAW,CACb,GAAGL,EAAI,SAAS,CAEf,IADA,IAAIe,EAAOR,EAAMK,MAAM,GACjBG,EAAKF,OAASN,EAAMM,QACzBE,EAAKD,KAAK,MAEXP,EAAQQ,EAET,IAAIC,EAASX,EAAWY,MAAMX,EAAUC,EAAMK,MAAM,GAAGM,OAAOT,EAAOI,cACjD,IAAVG,GACTP,EAAOK,KAAKE,GAGdN,EAAYN,EAAGM,UAMhB,OAJAF,EAAUL,EAAIS,MAAMF,IACTG,QACVJ,EAAOK,KAAKN,GAENC","file":"../../string/tokenize.js","sourcesContent":["define([\r\n\t\"dojo/_base/lang\",\r\n\t\"dojo/_base/sniff\"\t\r\n], function(lang, has){\r\n\tvar tokenize = lang.getObject(\"dojox.string\", true).tokenize;\r\n\r\n\ttokenize = function(/*String*/ str, /*RegExp*/ re, /*Function?*/ parseDelim, /*Object?*/ instance){\r\n\t\t// summary:\r\n\t\t//\t\tSplit a string by a regular expression with the ability to capture the delimiters\r\n\t\t// parseDelim:\r\n\t\t//\t\tEach group (excluding the 0 group) is passed as a parameter. If the function returns\r\n\t\t//\t\ta value, it's added to the list of tokens.\r\n\t\t// instance:\r\n\t\t//\t\tUsed as the \"this\" instance when calling parseDelim\r\n\t\tvar tokens = [];\r\n\t\tvar match, content, lastIndex = 0;\r\n\t\twhile(match = re.exec(str)){\r\n\t\t\tcontent = str.slice(lastIndex, re.lastIndex - match[0].length);\r\n\t\t\tif(content.length){\r\n\t\t\t\ttokens.push(content);\r\n\t\t\t}\r\n\t\t\tif(parseDelim){\r\n\t\t\t\tif(has(\"opera\")){\r\n\t\t\t\t\tvar copy = match.slice(0);\r\n\t\t\t\t\twhile(copy.length < match.length){\r\n\t\t\t\t\t\tcopy.push(null);\r\n\t\t\t\t\t}\r\n\t\t\t\t\tmatch = copy;\r\n\t\t\t\t}\r\n\t\t\t\tvar parsed = parseDelim.apply(instance, match.slice(1).concat(tokens.length));\r\n\t\t\t\tif(typeof parsed != \"undefined\"){\r\n\t\t\t\t\ttokens.push(parsed);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tlastIndex = re.lastIndex;\r\n\t\t}\r\n\t\tcontent = str.slice(lastIndex);\r\n\t\tif(content.length){\r\n\t\t\ttokens.push(content);\r\n\t\t}\r\n\t\treturn tokens;\r\n\t};\r\n\treturn tokenize;\r\n});\r\n"]}